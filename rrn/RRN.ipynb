{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/andrew/Desktop/sudoku/src/sudoku')\n",
    "\n",
    "from board import Board\n",
    "from grid_string import GridString, read_solutions_file\n",
    "from shuffler import Shuffler\n",
    "from shuffled_grid import ShuffledGrid\n",
    "from solutions import Solutions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/andrew/Desktop/sudoku/data/shuffled_puzzles.txt'\n",
    "with open(filename) as f:\n",
    "    lines = f.read().splitlines()\n",
    "puzzles = {}\n",
    "for line in lines:\n",
    "    puzzle, solution = line.split(',')\n",
    "    puzzles[GridString(puzzle)] = GridString(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_edges(dim_x, dim_y):\n",
    "    \"\"\"\n",
    "    Returns a 2-d array of (max_digit**2, n) where the i_th entry is a list of\n",
    "        other cells' indices that cell i shares a house with\n",
    "    \"\"\"\n",
    "    max_digit = dim_x*dim_y\n",
    "    edges = []\n",
    "    for row in range(max_digit):\n",
    "        row_edges = []\n",
    "        for col in range(max_digit):\n",
    "            # row & column\n",
    "            col_edges = {(row, i) for i in range(max_digit)}\n",
    "            col_edges |= {(i, col) for i in range(max_digit)}\n",
    "            \n",
    "            # box\n",
    "            x_min = (row // dim_x) * dim_x\n",
    "            y_min = (col // dim_y) * dim_y\n",
    "            col_edges |= set(itertools.product(range(x_min, x_min+dim_x), range(y_min, y_min+dim_y)))\n",
    "            \n",
    "            # removing self\n",
    "            col_edges -= {(row, col)}\n",
    "            col_edges = [row*max_digit + col for row, col in col_edges]\n",
    "            row_edges.append(sorted(col_edges))\n",
    "        edges.append(row_edges)\n",
    "    edges = torch.tensor(edges)\n",
    "    shape = edges.shape\n",
    "    return edges.reshape(max_digit**2, shape[2])\n",
    "\n",
    "def encode_input(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid()))\n",
    "\n",
    "def encode_output(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_n = 10\n",
    "train_puzzles = list(puzzles.keys())[0:train_n]\n",
    "train_solutions = [puzzles[p] for p in train_puzzles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_digit = train_puzzles[0].max_digit\n",
    "num_cells = max_digit**2\n",
    "cell_vec_dim = max_digit + 1\n",
    "train_x = torch.cat([encode_input(p) for p in train_puzzles]).reshape(train_n, num_cells)\n",
    "train_y = torch.cat([encode_output(p) for p in train_solutions]).reshape(train_n, num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        prev_layer_size = self.layer_sizes[0]\n",
    "        for size in self.layer_sizes[1:]:\n",
    "            self.layers.append(nn.Linear(prev_layer_size, size))\n",
    "            prev_layer_size = size\n",
    "\n",
    "    def forward(self, X):\n",
    "        vector = X\n",
    "        for layer in self.layers:\n",
    "            vector = layer(vector)\n",
    "        return vector\n",
    "\n",
    "class RRN(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, embed_size=16, hidden_layer_size=96):\n",
    "        super(RRN, self).__init__()\n",
    "        self.max_digit = dim_x * dim_y\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.edges = determine_edges(dim_x, dim_y)\n",
    "\n",
    "\n",
    "        self.embed_layer = nn.Embedding(self.max_digit+1, self.embed_size)\n",
    "        self.input_mlp = MLP([self.embed_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size])\n",
    "        \n",
    "        self.f = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_mlp = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_lstm = nn.LSTM(self.hidden_layer_size, self.hidden_layer_size)\n",
    "        self.r = MLP([self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.max_digit])\n",
    "    \n",
    "    def compute_messages(self, H):\n",
    "        messages = torch.zeros(H.shape)\n",
    "        batch_size = H.shape[0]\n",
    "        num_nodes = H.shape[1]\n",
    "        for puzzle_index in range(batch_size): # for puzzle in batch\n",
    "            messages[puzzle_index] = torch.tensor([torch.sum(H[puzzle_index][self.edges[n]]) for n in range(num_nodes)])\n",
    "        return messages\n",
    "                    \n",
    "\n",
    "    def forward(self, grids, iters):\n",
    "        batch_size = len(grids)\n",
    "        num_nodes = self.max_digit**2\n",
    "        edges_per_nodes = self.edges.shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        embeddings = self.embed_layer(grids)\n",
    "        X = self.input_mlp(embeddings)\n",
    "        H = torch.tensor(X)\n",
    "        g_lstm_h = H.reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "        g_lstm_c = torch.randn(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "#         g_lstm_h = torch.zeros(1, batch_size, 3)\n",
    "#         g_lstm_c = torch.zeros(1, batch_size, 3)\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(iters):\n",
    "            M = torch.zeros(batch_size, self.max_digit**2, self.hidden_layer_size)\n",
    "            for node in range(num_nodes):\n",
    "                msgs = torch.cat([self.f(torch.cat([H[:,node,:], H[:,other,:]], dim=1)) for other in self.edges[node]])\n",
    "                msgs = msgs.reshape(edges_per_nodes, batch_size, self.hidden_layer_size).permute(1,0,2)\n",
    "                M[:,n,:] = torch.sum(msgs, dim=1)\n",
    "            \n",
    "            input_to_g_lstm = self.g_mlp(torch.cat([X, M], dim=2)).reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "            \n",
    "            _, (g_lstm_h, g_lstm_c) = self.g_lstm(input_to_g_lstm, (g_lstm_h, g_lstm_c))\n",
    "            H = g_lstm_h.reshape(H.shape)\n",
    "            output = self.r(H)\n",
    "            \n",
    "            outputs.append(output)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RRN( dim_x=2, dim_y=2, embed_size=16, hidden_layer_size=96)\n",
    "predictions = [p.permute(0,2,1) for p in model(train_x, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.4395, grad_fn=<ThAddBackward>)\n",
      "tensor(44.4050, grad_fn=<ThAddBackward>)\n",
      "tensor(44.3720, grad_fn=<ThAddBackward>)\n",
      "tensor(44.3317, grad_fn=<ThAddBackward>)\n",
      "tensor(44.2935, grad_fn=<ThAddBackward>)\n",
      "tensor(44.2646, grad_fn=<ThAddBackward>)\n",
      "tensor(44.2286, grad_fn=<ThAddBackward>)\n",
      "tensor(44.1630, grad_fn=<ThAddBackward>)\n",
      "tensor(44.1055, grad_fn=<ThAddBackward>)\n",
      "tensor(44.0290, grad_fn=<ThAddBackward>)\n",
      "tensor(43.9269, grad_fn=<ThAddBackward>)\n",
      "tensor(43.7616, grad_fn=<ThAddBackward>)\n",
      "tensor(43.6199, grad_fn=<ThAddBackward>)\n",
      "tensor(43.3903, grad_fn=<ThAddBackward>)\n",
      "tensor(43.1125, grad_fn=<ThAddBackward>)\n",
      "tensor(42.7898, grad_fn=<ThAddBackward>)\n",
      "tensor(42.3937, grad_fn=<ThAddBackward>)\n",
      "tensor(41.8639, grad_fn=<ThAddBackward>)\n",
      "tensor(41.3130, grad_fn=<ThAddBackward>)\n",
      "tensor(40.6224, grad_fn=<ThAddBackward>)\n",
      "tensor(39.8641, grad_fn=<ThAddBackward>)\n",
      "tensor(39.0155, grad_fn=<ThAddBackward>)\n",
      "tensor(38.1631, grad_fn=<ThAddBackward>)\n",
      "tensor(37.2379, grad_fn=<ThAddBackward>)\n",
      "tensor(36.2883, grad_fn=<ThAddBackward>)\n",
      "tensor(35.3019, grad_fn=<ThAddBackward>)\n",
      "tensor(34.4091, grad_fn=<ThAddBackward>)\n",
      "tensor(33.6664, grad_fn=<ThAddBackward>)\n",
      "tensor(32.9803, grad_fn=<ThAddBackward>)\n",
      "tensor(32.3705, grad_fn=<ThAddBackward>)\n",
      "tensor(31.8371, grad_fn=<ThAddBackward>)\n",
      "tensor(31.3716, grad_fn=<ThAddBackward>)\n",
      "tensor(31.0042, grad_fn=<ThAddBackward>)\n",
      "tensor(30.7201, grad_fn=<ThAddBackward>)\n",
      "tensor(30.4622, grad_fn=<ThAddBackward>)\n",
      "tensor(30.2019, grad_fn=<ThAddBackward>)\n",
      "tensor(29.9330, grad_fn=<ThAddBackward>)\n",
      "tensor(29.6005, grad_fn=<ThAddBackward>)\n",
      "tensor(29.2132, grad_fn=<ThAddBackward>)\n",
      "tensor(28.8200, grad_fn=<ThAddBackward>)\n",
      "tensor(28.4345, grad_fn=<ThAddBackward>)\n",
      "tensor(28.0200, grad_fn=<ThAddBackward>)\n",
      "tensor(27.6298, grad_fn=<ThAddBackward>)\n",
      "tensor(27.2655, grad_fn=<ThAddBackward>)\n",
      "tensor(26.9137, grad_fn=<ThAddBackward>)\n",
      "tensor(26.4739, grad_fn=<ThAddBackward>)\n",
      "tensor(26.0446, grad_fn=<ThAddBackward>)\n",
      "tensor(25.5880, grad_fn=<ThAddBackward>)\n",
      "tensor(25.1160, grad_fn=<ThAddBackward>)\n",
      "tensor(24.6542, grad_fn=<ThAddBackward>)\n",
      "tensor(24.0948, grad_fn=<ThAddBackward>)\n",
      "tensor(23.6205, grad_fn=<ThAddBackward>)\n",
      "tensor(23.0353, grad_fn=<ThAddBackward>)\n",
      "tensor(22.5228, grad_fn=<ThAddBackward>)\n",
      "tensor(21.9865, grad_fn=<ThAddBackward>)\n",
      "tensor(21.4783, grad_fn=<ThAddBackward>)\n",
      "tensor(20.9753, grad_fn=<ThAddBackward>)\n",
      "tensor(20.4339, grad_fn=<ThAddBackward>)\n",
      "tensor(19.8635, grad_fn=<ThAddBackward>)\n",
      "tensor(19.3188, grad_fn=<ThAddBackward>)\n",
      "tensor(18.6476, grad_fn=<ThAddBackward>)\n",
      "tensor(18.0850, grad_fn=<ThAddBackward>)\n",
      "tensor(17.4552, grad_fn=<ThAddBackward>)\n",
      "tensor(16.9066, grad_fn=<ThAddBackward>)\n",
      "tensor(16.3159, grad_fn=<ThAddBackward>)\n",
      "tensor(15.8458, grad_fn=<ThAddBackward>)\n",
      "tensor(15.3198, grad_fn=<ThAddBackward>)\n",
      "tensor(14.8227, grad_fn=<ThAddBackward>)\n",
      "tensor(14.4300, grad_fn=<ThAddBackward>)\n",
      "tensor(13.9534, grad_fn=<ThAddBackward>)\n",
      "tensor(13.5735, grad_fn=<ThAddBackward>)\n",
      "tensor(13.1915, grad_fn=<ThAddBackward>)\n",
      "tensor(12.8276, grad_fn=<ThAddBackward>)\n",
      "tensor(12.5152, grad_fn=<ThAddBackward>)\n",
      "tensor(12.2196, grad_fn=<ThAddBackward>)\n",
      "tensor(11.9291, grad_fn=<ThAddBackward>)\n",
      "tensor(11.6751, grad_fn=<ThAddBackward>)\n",
      "tensor(11.3293, grad_fn=<ThAddBackward>)\n",
      "tensor(11.1446, grad_fn=<ThAddBackward>)\n",
      "tensor(10.8869, grad_fn=<ThAddBackward>)\n",
      "tensor(10.6549, grad_fn=<ThAddBackward>)\n",
      "tensor(10.4158, grad_fn=<ThAddBackward>)\n",
      "tensor(10.2679, grad_fn=<ThAddBackward>)\n",
      "tensor(10.0760, grad_fn=<ThAddBackward>)\n",
      "tensor(9.9092, grad_fn=<ThAddBackward>)\n",
      "tensor(9.7838, grad_fn=<ThAddBackward>)\n",
      "tensor(9.6877, grad_fn=<ThAddBackward>)\n",
      "tensor(9.4929, grad_fn=<ThAddBackward>)\n",
      "tensor(9.4092, grad_fn=<ThAddBackward>)\n",
      "tensor(9.3155, grad_fn=<ThAddBackward>)\n",
      "tensor(9.2957, grad_fn=<ThAddBackward>)\n",
      "tensor(9.1428, grad_fn=<ThAddBackward>)\n",
      "tensor(9.0842, grad_fn=<ThAddBackward>)\n",
      "tensor(9.0328, grad_fn=<ThAddBackward>)\n",
      "tensor(8.9427, grad_fn=<ThAddBackward>)\n",
      "tensor(8.9253, grad_fn=<ThAddBackward>)\n",
      "tensor(8.8727, grad_fn=<ThAddBackward>)\n",
      "tensor(8.8316, grad_fn=<ThAddBackward>)\n",
      "tensor(8.8145, grad_fn=<ThAddBackward>)\n",
      "tensor(8.7917, grad_fn=<ThAddBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = RRN( dim_x=2, dim_y=2, embed_size=4, hidden_layer_size=32)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = [p.permute(0,2,1) for p in model(train_x, 32)]\n",
    "#     print([F.cross_entropy(p, train_y) for p in predictions])\n",
    "    loss = sum([F.cross_entropy(p, train_y) for p in predictions])\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in tqdm_notebook(range(100)):\n",
    "    print(optimizer.step(closure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cell in determine_edges(2, 2):\n",
    "    print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 1), (3, 2), (3, 3), (4, 1), (4, 2), (4, 3), (5, 1), (5, 2), (5, 3)}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(itertools.product(range(3, 6), range(1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234341223414123"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_solutions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(2*3*4)).reshape(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor(range(2*3*4)).reshape(2,3,4)\n",
    "z = torch.zeros(m.shape)\n",
    "\n",
    "\n",
    "# print(m[0])\n",
    "# print(m[0][0])\n",
    "\n",
    "# m = torch.cat([m]*2)\n",
    "# m = m.reshape(2,2,3,4)\n",
    "# m = m.permute(1,2,0,3)\n",
    "# print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([m[:,0,:], m[:,1,:]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = torch.zeros(batch_size, self.max_digit**2, self.hidden_layer_size)\n",
    "for node in range(num_nodes):\n",
    "    M[:,n,:] = torch.sum([self.f(torch.cat([H[:,node,:], H[:,other,:]], dim=1)) for other in self.edges[node]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]],\n",
       "\n",
       "        [[20, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34],\n",
       "         [35, 36, 37, 38, 39]],\n",
       "\n",
       "        [[40, 41, 42, 43, 44],\n",
       "         [45, 46, 47, 48, 49],\n",
       "         [50, 51, 52, 53, 54],\n",
       "         [55, 56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor(range(3*4*5)).reshape(3,4,5)\n",
    "e = torch.tensor([[0,1], [1,2], [2,3], [3,0]])\n",
    "z = torch.zeros(3,4,5)\n",
    "for n in range(4):\n",
    "    # reshape()\n",
    "    a = torch.cat([m[:,other] for other in e[n]]).reshape(2, 3, 5).permute(1,0,2)\n",
    "    z[:,n,:] = torch.sum(a, dim=1)\n",
    "    \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.,   7.,   9.,  11.,  13.],\n",
       "         [ 15.,  17.,  19.,  21.,  23.],\n",
       "         [ 25.,  27.,  29.,  31.,  33.],\n",
       "         [ 15.,  17.,  19.,  21.,  23.]],\n",
       "\n",
       "        [[ 45.,  47.,  49.,  51.,  53.],\n",
       "         [ 55.,  57.,  59.,  61.,  63.],\n",
       "         [ 65.,  67.,  69.,  71.,  73.],\n",
       "         [ 55.,  57.,  59.,  61.,  63.]],\n",
       "\n",
       "        [[ 85.,  87.,  89.,  91.,  93.],\n",
       "         [ 95.,  97.,  99., 101., 103.],\n",
       "         [105., 107., 109., 111., 113.],\n",
       "         [ 95.,  97.,  99., 101., 103.]]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "widgets": {
   "state": {
    "dd0518e8c4b848a7aaf902e08c2f8858": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
