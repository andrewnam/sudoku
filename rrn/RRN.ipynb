{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/andrew/Desktop/sudoku/src/sudoku')\n",
    "\n",
    "from board import Board\n",
    "from grid_string import GridString, read_solutions_file\n",
    "from shuffler import Shuffler\n",
    "from shuffled_grid import ShuffledGrid\n",
    "from solutions import Solutions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = '/Users/andrew/Desktop/sudoku/data/shuffled_puzzles.txt'\n",
    "with open(filename) as f:\n",
    "    lines = f.read().splitlines()\n",
    "puzzles = {}\n",
    "for line in lines:\n",
    "    puzzle, solution = line.split(',')\n",
    "    puzzles[GridString(puzzle)] = GridString(solution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def determine_edges(dim_x, dim_y):\n",
    "    \"\"\"\n",
    "    Returns a 2-d array of (max_digit**2, n) where the i_th entry is a list of\n",
    "        other cells' indices that cell i shares a house with\n",
    "    \"\"\"\n",
    "    max_digit = dim_x*dim_y\n",
    "    edges = []\n",
    "    for row in range(max_digit):\n",
    "        row_edges = []\n",
    "        for col in range(max_digit):\n",
    "            # row & column\n",
    "            col_edges = {(row, i) for i in range(max_digit)}\n",
    "            col_edges |= {(i, col) for i in range(max_digit)}\n",
    "            \n",
    "            # box\n",
    "            x_min = (row // dim_x) * dim_x\n",
    "            y_min = (col // dim_y) * dim_y\n",
    "            col_edges |= set(itertools.product(range(x_min, x_min+dim_x), range(y_min, y_min+dim_y)))\n",
    "            \n",
    "            # removing self\n",
    "            col_edges -= {(row, col)}\n",
    "            col_edges = [row*max_digit + col for row, col in col_edges]\n",
    "            row_edges.append(sorted(col_edges))\n",
    "        edges.append(row_edges)\n",
    "    edges = torch.tensor(edges)\n",
    "    shape = edges.shape\n",
    "    return edges.reshape(max_digit**2, shape[2])\n",
    "\n",
    "def encode_input(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid()))\n",
    "\n",
    "def encode_output(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_n = 10\n",
    "train_puzzles = list(puzzles.keys())[0:train_n]\n",
    "train_solutions = [puzzles[p] for p in train_puzzles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_digit = train_puzzles[0].max_digit\n",
    "num_cells = max_digit**2\n",
    "cell_vec_dim = max_digit + 1\n",
    "train_x = torch.cat([encode_input(p) for p in train_puzzles]).reshape(train_n, num_cells)\n",
    "train_y = torch.cat([encode_output(p) for p in train_solutions]).reshape(train_n, num_cells)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        \n",
    "        prev_layer_size = self.layer_sizes[0]\n",
    "        for size in self.layer_sizes[1:]:\n",
    "            self.layers.append(nn.Linear(prev_layer_size, size))\n",
    "            prev_layer_size = size\n",
    "\n",
    "    def forward(self, X):\n",
    "        vector = X\n",
    "        for layer in self.layers:\n",
    "            vector = layer(vector)\n",
    "        return vector\n",
    "\n",
    "class RRN(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, embed_size=16, hidden_layer_size=96):\n",
    "        super(RRN, self).__init__()\n",
    "        self.max_digit = dim_x * dim_y\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.edges = determine_edges(dim_x, dim_y)\n",
    "\n",
    "\n",
    "        self.embed_layer = nn.Embedding(self.max_digit+1, self.embed_size)\n",
    "        self.input_mlp = MLP([self.embed_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size])\n",
    "        \n",
    "        self.f = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_mlp = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_lstm = nn.LSTM(self.hidden_layer_size, self.hidden_layer_size)\n",
    "        self.r = MLP([self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.max_digit])\n",
    "    \n",
    "    def compute_messages(self, H):\n",
    "        messages = torch.zeros(H.shape)\n",
    "        batch_size = H.shape[0]\n",
    "        num_nodes = H.shape[1]\n",
    "        for puzzle_index in range(batch_size): # for puzzle in batch\n",
    "            messages[puzzle_index] = torch.tensor([torch.sum(H[puzzle_index][self.edges[n]]) for n in range(num_nodes)])\n",
    "        return messages\n",
    "                    \n",
    "\n",
    "    def forward(self, grids, iters):\n",
    "        batch_size = len(grids)\n",
    "        num_nodes = self.max_digit**2\n",
    "        edges_per_nodes = self.edges.shape[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        embeddings = self.embed_layer(grids)\n",
    "        X = self.input_mlp(embeddings)\n",
    "        H = torch.tensor(X)\n",
    "        g_lstm_h = H.reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "        g_lstm_c = torch.randn(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "#         g_lstm_h = torch.zeros(1, batch_size, 3)\n",
    "#         g_lstm_c = torch.zeros(1, batch_size, 3)\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(iters):\n",
    "            M = torch.zeros(batch_size, self.max_digit**2, self.hidden_layer_size)\n",
    "            for node in range(num_nodes):\n",
    "                msgs = torch.cat([self.f(torch.cat([H[:,node,:], H[:,other,:]], dim=1)) for other in self.edges[node]])\n",
    "                msgs = msgs.reshape(edges_per_nodes, batch_size, self.hidden_layer_size).permute(1,0,2)\n",
    "                M[:,n,:] = torch.sum(msgs, dim=1)\n",
    "            \n",
    "            input_to_g_lstm = self.g_mlp(torch.cat([X, M], dim=2)).reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "            \n",
    "            _, (g_lstm_h, g_lstm_c) = self.g_lstm(input_to_g_lstm, (g_lstm_h, g_lstm_c))\n",
    "            H = g_lstm_h.reshape(H.shape)\n",
    "            output = self.r(H)\n",
    "            \n",
    "            outputs.append(output)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = RRN( dim_x=2, dim_y=2, embed_size=16, hidden_layer_size=96)\n",
    "predictions = [p.permute(0,2,1) for p in model(train_x, 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor(1.4017, grad_fn=<NllLoss2DBackward>), tensor(1.3982, grad_fn=<NllLoss2DBackward>), tensor(1.3966, grad_fn=<NllLoss2DBackward>), tensor(1.3959, grad_fn=<NllLoss2DBackward>), tensor(1.3957, grad_fn=<NllLoss2DBackward>), tensor(1.3957, grad_fn=<NllLoss2DBackward>), tensor(1.3957, grad_fn=<NllLoss2DBackward>), tensor(1.3957, grad_fn=<NllLoss2DBackward>), tensor(1.3957, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>), tensor(1.3958, grad_fn=<NllLoss2DBackward>)]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "zero-dimensional tensor (at position 0) cannot be concatenated",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-466-f752342fac33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/andrew/anaconda/lib/python3.6/site-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     55\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-466-f752342fac33>\u001b[0m in \u001b[0;36mclosure\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: zero-dimensional tensor (at position 0) cannot be concatenated"
     ]
    }
   ],
   "source": [
    "model = RRN( dim_x=2, dim_y=2, embed_size=4, hidden_layer_size=32)\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = [p.permute(0,2,1) for p in model(train_x, 32)]\n",
    "    print([F.cross_entropy(p, train_y) for p in predictions])\n",
    "    loss = torch.sum(torch.cat([F.cross_entropy(p, train_y) for p in predictions]))\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in range(100):\n",
    "    print(optimizer.step(closure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for cell in determine_edges(2, 2):\n",
    "    print(cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(3, 1), (3, 2), (3, 3), (4, 1), (4, 2), (4, 3), (5, 1), (5, 2), (5, 3)}"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(itertools.product(range(3, 6), range(1, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1234341223414123"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_solutions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]],\n",
       "\n",
       "        [[12, 13, 14, 15],\n",
       "         [16, 17, 18, 19],\n",
       "         [20, 21, 22, 23]]])"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(range(2*3*4)).reshape(2,3,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor(range(2*3*4)).reshape(2,3,4)\n",
    "z = torch.zeros(m.shape)\n",
    "\n",
    "\n",
    "# print(m[0])\n",
    "# print(m[0][0])\n",
    "\n",
    "# m = torch.cat([m]*2)\n",
    "# m = m.reshape(2,2,3,4)\n",
    "# m = m.permute(1,2,0,3)\n",
    "# print(m.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 4,  5,  6,  7],\n",
       "        [16, 17, 18, 19]])"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,1,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3,  4,  5,  6,  7],\n",
       "        [12, 13, 14, 15, 16, 17, 18, 19]])"
      ]
     },
     "execution_count": 350,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cat([m[:,0,:], m[:,1,:]], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "M = torch.zeros(batch_size, self.max_digit**2, self.hidden_layer_size)\n",
    "for node in range(num_nodes):\n",
    "    M[:,n,:] = torch.sum([self.f(torch.cat([H[:,node,:], H[:,other,:]], dim=1)) for other in self.edges[node]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3,  4],\n",
       "         [ 5,  6,  7,  8,  9],\n",
       "         [10, 11, 12, 13, 14],\n",
       "         [15, 16, 17, 18, 19]],\n",
       "\n",
       "        [[20, 21, 22, 23, 24],\n",
       "         [25, 26, 27, 28, 29],\n",
       "         [30, 31, 32, 33, 34],\n",
       "         [35, 36, 37, 38, 39]],\n",
       "\n",
       "        [[40, 41, 42, 43, 44],\n",
       "         [45, 46, 47, 48, 49],\n",
       "         [50, 51, 52, 53, 54],\n",
       "         [55, 56, 57, 58, 59]]])"
      ]
     },
     "execution_count": 404,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = torch.tensor(range(3*4*5)).reshape(3,4,5)\n",
    "e = torch.tensor([[0,1], [1,2], [2,3], [3,0]])\n",
    "z = torch.zeros(3,4,5)\n",
    "for n in range(4):\n",
    "    # reshape()\n",
    "    a = torch.cat([m[:,other] for other in e[n]]).reshape(2, 3, 5).permute(1,0,2)\n",
    "    z[:,n,:] = torch.sum(a, dim=1)\n",
    "    \n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.,   7.,   9.,  11.,  13.],\n",
       "         [ 15.,  17.,  19.,  21.,  23.],\n",
       "         [ 25.,  27.,  29.,  31.,  33.],\n",
       "         [ 15.,  17.,  19.,  21.,  23.]],\n",
       "\n",
       "        [[ 45.,  47.,  49.,  51.,  53.],\n",
       "         [ 55.,  57.,  59.,  61.,  63.],\n",
       "         [ 65.,  67.,  69.,  71.,  73.],\n",
       "         [ 55.,  57.,  59.,  61.,  63.]],\n",
       "\n",
       "        [[ 85.,  87.,  89.,  91.,  93.],\n",
       "         [ 95.,  97.,  99., 101., 103.],\n",
       "         [105., 107., 109., 111., 113.],\n",
       "         [ 95.,  97.,  99., 101., 103.]]])"
      ]
     },
     "execution_count": 402,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [12, 13, 14, 15]])"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
