{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/andrew/Desktop/sudoku/src/sudoku')\n",
    "\n",
    "from board import Board\n",
    "from solutions import Solutions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x113383b90>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_encode(board_string):\n",
    "    dim_x, dim_y, board = board_string.split('.')\n",
    "    max_digit = int(dim_x) * int(dim_y)\n",
    "    vector = np.zeros((max_digit*len(board),), dtype=np.float64)\n",
    "    for i in range(len(board)):\n",
    "        if board[i] != '0':\n",
    "            vector[i*max_digit + int(board[i]) - 1] = 1\n",
    "        else:\n",
    "            vector[i*max_digit:(i+1)*max_digit] = 1/max_digit\n",
    "    return vector\n",
    "\n",
    "def get_board_entries(board_string):\n",
    "    return np.array(list(board_string[4:]), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_numbers(seed_board_string, number_orders):\n",
    "    \"\"\"\n",
    "    Given a seed_board string and a string with the new order for top row of board, generates derivative board\n",
    "    e.g.\n",
    "    >>> shuffle_numbers('2.2.0204030120400400', ['2143'])\n",
    "    ['2.2.0103040210300300']\n",
    "    \"\"\"\n",
    "    max_digit = int(seed_board_string[0]) * int(seed_board_string[2])\n",
    "    digits = seed_board_string[4:]\n",
    "    assert np.all([int(digits[i]) == i+1 or int(digits[i]) == 0 for i in range(max_digit)]) # check if seed\n",
    "    if type(number_orders) == str:\n",
    "        number_orders = [number_orders]\n",
    "        \n",
    "    all_digits = {str(i) for i in range(1, max_digit+1)}\n",
    "    shuffled_board_strings = []\n",
    "    for number_order in number_orders:\n",
    "        assert len(number_order) == max_digit\n",
    "        mapping = {str(i+1): str(number_order[i]) for i in range(max_digit)}\n",
    "        assert set(mapping.values()) == all_digits\n",
    "        shuffled_board_string = seed_board_string[:4]\n",
    "        shuffled_board_string += ''.join([mapping[d] if d != '0' else '0' for d in digits])\n",
    "        shuffled_board_strings.append(shuffled_board_string)\n",
    "    \n",
    "    return shuffled_board_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_derivatives(puzzles, solutions, num_derivatives=0):\n",
    "    \"\"\"\n",
    "    puzzles: list of seed Boards\n",
    "    solutions: Solutions\n",
    "    num_derivatives: max number of derivatives to generate per seed. Default: 0 -> all\n",
    "    returns\n",
    "    derivative_puzzles: dict - seed board string -> list of derivative board strings\n",
    "    derivative_puzzle_solutions: dict - derivative board string -> derivative board solution string\n",
    "    \"\"\"\n",
    "    max_digit = puzzles[0].board.shape[0]\n",
    "    all_digits_string = ''.join([str(i) for i in range(1, max_digit+1)])\n",
    "    permutations = [''.join(lst) for lst in itertools.permutations(all_digits_string, max_digit)]\n",
    "    random.shuffle(permutations)\n",
    "    if num_derivatives > 0:\n",
    "        permutations = permutations[:num_derivatives]\n",
    "    derivative_puzzles = {}\n",
    "    derivative_puzzle_solutions = {}\n",
    "    for puzzle in puzzles:\n",
    "        puzzle_string = puzzle.stringify()\n",
    "        derivatives = shuffle_numbers(puzzle_string, permutations)\n",
    "        derivative_solutions = shuffle_numbers(solutions[puzzle].stringify(), permutations)\n",
    "        derivative_puzzles[puzzle_string] = derivatives\n",
    "        for i in range(len(permutations)):\n",
    "            derivative_puzzle_solutions[derivatives[i]] = derivative_solutions[i]\n",
    "    return derivative_puzzles, derivative_puzzle_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, boundaries):\n",
    "    \"\"\"\n",
    "    Shuffles and splits data according to the sorted boundaries set\n",
    "    \"\"\"\n",
    "    assert boundaries[0] > 0 and boundaries[-1] < 1 and boundaries == sorted(boundaries)\n",
    "    assert len(data) > len(boundaries)\n",
    "    \n",
    "    data = list(data)\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    split = []\n",
    "    last_boundary = 0\n",
    "    for boundary in boundaries + [1]:\n",
    "        next_boundary = int(len(data) * boundary)\n",
    "        split.append(data[last_boundary:next_boundary])\n",
    "        last_boundary = next_boundary\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_dataset(seed_puzzles, solutions, boundaries, num_derivatives=0):\n",
    "    \"\"\"\n",
    "    puzzles: list of puzzle\n",
    "    \"\"\"\n",
    "    derivative_puzzles, derivative_puzzle_solutions = generate_derivatives(seed_puzzles, solutions, num_derivatives)\n",
    "\n",
    "    train_seeds, valid_seeds, test_seeds = split_data([p.stringify() for p in seed_puzzles], boundaries)\n",
    "    train_seeds_derivs = utils.flatten([derivative_puzzles[puzzle] for puzzle in train_seeds])\n",
    "    train_puzzles, valid_deriv_puzzles, test_deriv_puzzles = split_data(train_seeds_derivs, boundaries)\n",
    "\n",
    "    train = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in train_puzzles}\n",
    "    valid_deriv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in valid_deriv_puzzles}\n",
    "    test_deriv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in test_deriv_puzzles}\n",
    "\n",
    "    valid_nonderiv_puzzles = utils.flatten([derivative_puzzles[puzzle] for puzzle in valid_seeds])\n",
    "    valid_nonderiv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in valid_nonderiv_puzzles}\n",
    "    test_nonderiv_puzzles = utils.flatten([derivative_puzzles[puzzle] for puzzle in test_seeds])\n",
    "    test_nonderiv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in test_nonderiv_puzzles}\n",
    "\n",
    "    # sanity check\n",
    "    assert not train.keys() & valid_deriv.keys()\n",
    "    assert not train.keys() & test_deriv.keys()\n",
    "    assert not train.keys() & valid_nonderiv.keys()\n",
    "    assert not train.keys() & test_nonderiv.keys()\n",
    "    assert not valid_deriv.keys() & test_deriv.keys()\n",
    "    assert not valid_deriv.keys() & valid_nonderiv.keys()\n",
    "    assert not valid_deriv.keys() & test_nonderiv.keys()\n",
    "    assert not test_deriv.keys() & valid_nonderiv.keys()\n",
    "    assert not test_deriv.keys() & test_nonderiv.keys()\n",
    "    assert not valid_nonderiv.keys() & test_nonderiv.keys()\n",
    "    \n",
    "    return train, valid_deriv, test_deriv, valid_nonderiv, test_nonderiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 64\n",
      "5 357\n",
      "6 883\n",
      "7 1584\n",
      "8 2384\n",
      "9 3309\n",
      "10 4149\n",
      "11 4754\n",
      "12 4841\n",
      "13 3741\n",
      "14 1391\n",
      "15 192\n",
      "16 12\n"
     ]
    }
   ],
   "source": [
    "solutions = Solutions('/Users/andrew/Desktop/sudoku/data/solutions5.txt')\n",
    "puzzles = solutions.get_puzzles_by_hints()\n",
    "for hints in sorted(puzzles):\n",
    "    print(hints, len(puzzles[hints]))\n",
    "\n",
    "train, valid_deriv, test_deriv, valid_nonderiv, test_nonderiv = generate_dataset(puzzles[4], solutions, [.7, .8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, max_digit):\n",
    "        super(Linear, self).__init__()\n",
    "        self.max_digit = max_digit\n",
    "        self.linear = nn.Linear(self.max_digit**3, self.max_digit**3)\n",
    "        self.softmax = nn.Softmax(dim=2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        pre_output = self.linear(X).reshape(X.shape[0], self.max_digit**2, self.max_digit)\n",
    "        return self.softmax(pre_output)\n",
    "#         predictions = [softmax(pre_output[i*self.max_digit:(i+1)*self.max_digit]) for i in range(self.max_digit**2)]\n",
    "        \n",
    "#         return torch.stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = torch.randn(2, 3, 4)\n",
    "b = nn.Softmax(dim=2)(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7624,  0.9520,  0.8139,  0.5260],\n",
       "         [-0.5523, -0.6327,  0.0902,  0.5165],\n",
       "         [-0.8378,  0.2764, -1.8262, -0.6584]],\n",
       "\n",
       "        [[-0.1834, -0.3537,  1.6652,  0.3598],\n",
       "         [ 0.8794, -1.0414,  0.7348,  2.2601],\n",
       "         [-1.0239, -0.6942, -0.8388, -1.1062]]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.2468, 0.2984, 0.2599, 0.1949],\n",
       "         [0.1485, 0.1370, 0.2823, 0.4323],\n",
       "         [0.1781, 0.5426, 0.0663, 0.2131]],\n",
       "\n",
       "        [[0.1009, 0.0851, 0.6405, 0.1736],\n",
       "         [0.1670, 0.0245, 0.1445, 0.6641],\n",
       "         [0.2215, 0.3080, 0.2665, 0.2040]]])"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_XY(puzzles):\n",
    "    \"\"\"\n",
    "    puzzles: dict - puzzle board string -> solution board string\n",
    "    \"\"\"\n",
    "    keys = sorted(puzzles)\n",
    "    X = torch.tensor([vector_encode(p) for p in keys])\n",
    "    Y = torch.tensor([get_board_entries(puzzles[p]) for p in keys], dtype=torch.int64) - 1\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_digit = 4\n",
    "model = Linear(max_digit)\n",
    "model.double()\n",
    "\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.8)\n",
    "X, Y = generate_XY(train)\n",
    "# X = X[:2]\n",
    "# Y = Y[:2]\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(X)\n",
    "    total_cells = Y.shape[0]*Y.shape[1]\n",
    "    flattened_prediction = prediction.reshape(total_cells, max_digit)\n",
    "    flattened_Y = Y.reshape(total_cells)\n",
    "    loss = nn.functional.nll_loss(flattened_prediction, flattened_Y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2502, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2503, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2504, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2506, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2507, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2508, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2509, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2510, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2511, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2512, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2513, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2514, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2515, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2516, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2518, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2519, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2520, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2521, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2522, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2523, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2524, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2525, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2526, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2528, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2529, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2530, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2531, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2532, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2533, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2534, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2535, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2536, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2538, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2539, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2540, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2541, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2542, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2543, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2544, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2545, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2546, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2548, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2549, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2550, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2551, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2552, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2553, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2554, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2555, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2557, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2558, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2559, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2560, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2561, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2562, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2563, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2564, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2566, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2567, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2568, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2569, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2570, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2571, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2572, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2574, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2575, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2576, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2577, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2578, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2579, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2580, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2582, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2583, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2584, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2585, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2586, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2587, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2588, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2590, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2591, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2592, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2593, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2594, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2595, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2596, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2598, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2599, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2600, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2601, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2602, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2603, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2604, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2606, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2607, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2608, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2609, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2610, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2611, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2613, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2614, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2615, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2616, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2617, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2618, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2620, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2621, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2622, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2623, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2624, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2625, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2626, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2628, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2629, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2630, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2631, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2632, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2633, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2635, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2636, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2637, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2638, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2639, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2641, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2642, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2643, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2644, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2645, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2646, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2648, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2649, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2650, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2651, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2652, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2653, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2655, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2656, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2657, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2658, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2659, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2661, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2662, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2663, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2664, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2665, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2666, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2668, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2669, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2670, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2671, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2672, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2674, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2675, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2676, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2677, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2678, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2680, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2681, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2682, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2683, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2684, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2686, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2687, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2688, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2689, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2690, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2692, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2693, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2694, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2695, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2696, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2698, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2699, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2700, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2701, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2702, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2704, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2705, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2706, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2707, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2708, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2710, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2711, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2712, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2713, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2714, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2716, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2717, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2718, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2719, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2720, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2722, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2723, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2724, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2725, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2726, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2728, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2729, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2730, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2731, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2733, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2734, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2735, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2736, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2737, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2739, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2740, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2741, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2742, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2744, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2745, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2746, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2747, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2748, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2750, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2751, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2752, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2753, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2755, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2756, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2757, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2758, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2759, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2761, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2762, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2763, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2764, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2766, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2767, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2768, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2769, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2771, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2772, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2773, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2774, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2775, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2777, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2778, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2779, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2780, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2782, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2783, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2784, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2785, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2787, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2788, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2789, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2790, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2792, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2793, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2794, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2795, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2796, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2798, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2799, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2800, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2801, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2803, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2804, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2805, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2806, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2808, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2809, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2810, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2811, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2813, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2814, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2815, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2816, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2818, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2819, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2820, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2821, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2823, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2824, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2825, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2826, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2828, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2829, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2830, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2831, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2833, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2834, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2835, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2836, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2838, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2839, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2840, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2842, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2843, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2844, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2845, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2847, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2848, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2849, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2850, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2852, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2853, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2854, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2855, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2857, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2858, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2859, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2860, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2862, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2863, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2864, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2866, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2867, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2868, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2869, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2871, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2872, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2873, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2874, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2876, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2877, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2878, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2879, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2881, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2882, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2883, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2885, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2886, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2887, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2888, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2890, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2891, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2892, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2894, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2895, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2896, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2897, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2899, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2900, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2901, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2902, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2904, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2905, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2906, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2908, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2909, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2910, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2911, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2913, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2914, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2915, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2917, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2918, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2919, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2920, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2922, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2923, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2924, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2926, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2927, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2928, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2929, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2931, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2932, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2933, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2935, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2936, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2937, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2938, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2940, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2941, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2942, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2944, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2945, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2946, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2948, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2949, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2950, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2951, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2953, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2954, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2955, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2957, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2958, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2959, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2961, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2962, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2963, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2964, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2966, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2967, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2968, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2970, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2971, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2972, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2974, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2975, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2976, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2977, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2979, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2980, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2981, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2983, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2984, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2985, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2987, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2988, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2989, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2991, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2992, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2993, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2994, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2996, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2997, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2998, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3000, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3001, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3002, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3004, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3005, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3006, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3008, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3009, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3010, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3012, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3013, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3014, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3015, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3017, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3018, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3019, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3021, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3022, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3023, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3025, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3026, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3027, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3029, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3030, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3031, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3033, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3034, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3035, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3037, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3038, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3039, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3041, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3042, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3043, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3045, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3046, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3047, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3049, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3050, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3051, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3052, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3054, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3055, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3056, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3058, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3059, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3060, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3062, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3063, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3064, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3066, grad_fn=<NllLossBackward>)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[4.8582e-24, 3.9519e-22, 4.2952e-24, 1.0000e+00],\n",
       "         [8.2320e-14, 1.0000e+00, 3.0586e-08, 2.4407e-12],\n",
       "         [1.0000e+00, 4.2197e-22, 1.7555e-21, 1.6835e-21],\n",
       "         [1.8346e-11, 1.3179e-06, 1.0000e+00, 6.1353e-12],\n",
       "         [4.1912e-12, 1.6680e-06, 1.0000e+00, 1.1903e-12],\n",
       "         [1.0000e+00, 6.1607e-24, 9.3786e-22, 1.7533e-22],\n",
       "         [5.0747e-23, 2.7342e-23, 4.3179e-23, 1.0000e+00],\n",
       "         [1.0154e-13, 1.0000e+00, 2.5331e-08, 1.1036e-12],\n",
       "         [1.0000e+00, 1.0886e-23, 6.4354e-23, 1.0542e-22],\n",
       "         [1.3856e-12, 1.4528e-06, 1.0000e+00, 1.4370e-12],\n",
       "         [6.6631e-12, 1.0000e+00, 1.3912e-06, 1.0697e-11],\n",
       "         [2.2263e-22, 2.3738e-23, 1.0526e-22, 1.0000e+00],\n",
       "         [7.7964e-13, 1.0000e+00, 3.1206e-08, 1.2690e-12],\n",
       "         [5.9563e-22, 9.2355e-22, 2.1416e-22, 1.0000e+00],\n",
       "         [2.1281e-11, 2.1017e-06, 1.0000e+00, 1.8384e-12],\n",
       "         [1.0000e+00, 6.7983e-22, 6.6278e-23, 4.6920e-22]]],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot unsqueeze empty tensor",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m    Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-140-f9a4d7bbf4b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/andrew/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-2d385da477f2>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mpre_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_digit\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_digit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpre_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#         predictions = [softmax(pre_output[i*self.max_digit:(i+1)*self.max_digit]) for i in range(self.max_digit**2)]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda/lib/python3.6/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/andrew/anaconda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1024\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot unsqueeze empty tensor"
     ]
    }
   ],
   "source": [
    "np.argmax(model(X[2:3]).detach().numpy(), axis=2) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-141-a584ddd3de8d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    }
   ],
   "source": [
    "print(Y[2] + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n",
      "torch.Size([16, 4])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "max_digit = 4\n",
    "model = Linear(max_digit)\n",
    "model.double()\n",
    "\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.8)\n",
    "X = torch.tensor(vector_encode('2.2.0134432100400010'))\n",
    "Y = torch.tensor(get_board_entries('2.2.2134432112433412'), dtype=torch.int64) - 1\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(X)\n",
    "    print(prediction.shape)\n",
    "    loss = nn.functional.nll_loss(prediction, Y)\n",
    "#     print(loss)\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in range(4):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.item())\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict, no need to track gradient here\n",
    "    with torch.no_grad():\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.detach().numpy()\n",
    "    # draw the result\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "        plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "    plt.savefig('predict%d.pdf'%i)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "board = Board.loadFromString('2.2.0134432100400010')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3, 4],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 0, 4, 0],\n",
       "       [0, 0, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2134432112433412'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2.2.2134432112433412'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_numbers(seed_board_string, number_orders):\n",
    "    max_digit = int(seed_board_string[0]) * int(seed_board_string[2])\n",
    "    digits = seed_board_string[4:]\n",
    "    assert np.all([int(digits[i]) == i+1 or int(digits[i]) == 0 for i in range(max_digit)]) # check if seed\n",
    "    if type(number_orders) == str:\n",
    "        number_orders = [number_orders]\n",
    "        \n",
    "    all_digits = {str(i) for i in range(1, max_digit+1)}\n",
    "    shuffled_board_strings = []\n",
    "    for number_order in number_orders:\n",
    "        assert len(number_order) == max_digit\n",
    "        mapping = {str(i+1): str(number_order[i]) for i in range(max_digit)}\n",
    "        assert set(mapping.values()) == all_digits\n",
    "        shuffled_board_string = seed_board_string[:4]\n",
    "        shuffled_board_string += ''.join([mapping[d] for d in digits])\n",
    "        shuffled_board_strings.append(shuffled_board_string)\n",
    "    \n",
    "    return shuffled_board_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
