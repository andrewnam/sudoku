{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "import sys\n",
    "sys.path.append('/Users/andrew/Desktop/sudoku/src/sudoku')\n",
    "\n",
    "from board import Board\n",
    "from solutions import Solutions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x10f59cb50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set random seed to 0\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "softmax = nn.Softmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vector_encode(board_string):\n",
    "    dim_x, dim_y, board = board_string.split('.')\n",
    "    max_digit = int(dim_x) * int(dim_y)\n",
    "    vector = np.zeros((max_digit*len(board),), dtype=np.float64)\n",
    "    for i in range(len(board)):\n",
    "        if board[i] != '0':\n",
    "            vector[i*max_digit + int(board[i]) - 1] = 1\n",
    "        else:\n",
    "            vector[i*max_digit:(i+1)*max_digit] = 1/max_digit\n",
    "    return vector\n",
    "\n",
    "def get_board_entries(board_string):\n",
    "    return np.array(list(board_string[4:]), dtype=np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self, max_digit):\n",
    "        super(Linear, self).__init__()\n",
    "        self.max_digit = max_digit\n",
    "        self.linear = nn.Linear(self.max_digit**3, self.max_digit**3)\n",
    "\n",
    "    def forward(self, X):\n",
    "        pre_output = self.linear(X)\n",
    "        predictions = [softmax(pre_output[i*self.max_digit:(i+1)*self.max_digit]) for i in range(self.max_digit**2)]\n",
    "        return torch.stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "max_digit = 4\n",
    "model = Linear(max_digit)\n",
    "model.double()\n",
    "\n",
    "optimizer = optim.LBFGS(model.parameters(), lr=0.8)\n",
    "X = torch.tensor(vector_encode('2.2.0134432100400010'))\n",
    "Y = torch.tensor(get_board_entries('2.2.2134432112433412'), dtype=torch.int64) - 1\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    prediction = model(X)\n",
    "    loss = nn.functional.nll_loss(prediction, Y)\n",
    "    print(loss)\n",
    "    loss.backward()\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(-0.2470, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2514, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.2802, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3131, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3501, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.3910, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.4351, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.4815, grad_fn=<NllLossBackward>)\n",
      "tensor(-0.5288, grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n",
      "tensor(-1., grad_fn=<NllLossBackward>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andrew/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:9: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    optimizer.step(closure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 64\n",
      "5 357\n",
      "6 883\n",
      "7 1584\n",
      "8 2384\n",
      "9 3309\n",
      "10 4149\n",
      "11 4754\n",
      "12 4841\n",
      "13 3741\n",
      "14 1391\n",
      "15 192\n",
      "16 12\n"
     ]
    }
   ],
   "source": [
    "solutions = Solutions('/Users/andrew/Desktop/sudoku/data/solutions5.txt')\n",
    "puzzles = solutions.get_puzzles_by_hints()\n",
    "for hints in sorted(puzzles):\n",
    "    print(hints, len(puzzles[hints]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_numbers(seed_board_string, number_orders):\n",
    "    \"\"\"\n",
    "    Given a seed_board string and a string with the new order for top row of board, generates derivative board\n",
    "    e.g.\n",
    "    >>> shuffle_numbers('2.2.0204030120400400', ['2143'])\n",
    "    ['2.2.0103040210300300']\n",
    "    \"\"\"\n",
    "    max_digit = int(seed_board_string[0]) * int(seed_board_string[2])\n",
    "    digits = seed_board_string[4:]\n",
    "    assert np.all([int(digits[i]) == i+1 or int(digits[i]) == 0 for i in range(max_digit)]) # check if seed\n",
    "    if type(number_orders) == str:\n",
    "        number_orders = [number_orders]\n",
    "        \n",
    "    all_digits = {str(i) for i in range(1, max_digit+1)}\n",
    "    shuffled_board_strings = []\n",
    "    for number_order in number_orders:\n",
    "        assert len(number_order) == max_digit\n",
    "        mapping = {str(i+1): str(number_order[i]) for i in range(max_digit)}\n",
    "        assert set(mapping.values()) == all_digits\n",
    "        shuffled_board_string = seed_board_string[:4]\n",
    "        shuffled_board_string += ''.join([mapping[d] if d != '0' else '0' for d in digits])\n",
    "        shuffled_board_strings.append(shuffled_board_string)\n",
    "    \n",
    "    return shuffled_board_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_derivatives(puzzles, solutions, num_derivatives=0):\n",
    "    \"\"\"\n",
    "    puzzles: list of seed Boards\n",
    "    solutions: Solutions\n",
    "    num_derivatives: max number of derivatives to generate per seed. Default: 0 -> all\n",
    "    returns\n",
    "    derivative_puzzles: dict - seed board string -> list of derivative board strings\n",
    "    derivative_puzzle_solutions: dict - derivative board string -> derivative board solution string\n",
    "    \"\"\"\n",
    "    max_digit = puzzles[0].board.shape[0]\n",
    "    all_digits_string = ''.join([str(i) for i in range(1, max_digit+1)])\n",
    "    permutations = [''.join(lst) for lst in itertools.permutations(all_digits_string, max_digit)]\n",
    "    random.shuffle(permutations)\n",
    "    if num_derivatives > 0:\n",
    "        permutations = permutations[:num_derivatives]\n",
    "    derivative_puzzles = {}\n",
    "    derivative_puzzle_solutions = {}\n",
    "    for puzzle in puzzles:\n",
    "        puzzle_string = puzzle.stringify()\n",
    "        derivatives = shuffle_numbers(puzzle_string, permutations)\n",
    "        derivative_solutions = shuffle_numbers(solutions[puzzle].stringify(), permutations)\n",
    "        derivative_puzzles[puzzle_string] = derivatives\n",
    "        for i in range(len(permutations)):\n",
    "            derivative_puzzle_solutions[derivatives[i]] = derivative_solutions[i]\n",
    "    return derivative_puzzles, derivative_puzzle_solutions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data, boundaries):\n",
    "    \"\"\"\n",
    "    Shuffles and splits data according to the sorted boundaries set\n",
    "    \"\"\"\n",
    "    assert boundaries[0] > 0 and boundaries[-1] < 1 and boundaries == sorted(boundaries)\n",
    "    assert len(data) > len(boundaries)\n",
    "    \n",
    "    data = list(data)\n",
    "    np.random.shuffle(data)\n",
    "    \n",
    "    split = []\n",
    "    last_boundary = 0\n",
    "    for boundary in boundaries + [1]:\n",
    "        next_boundary = int(len(data) * boundary)\n",
    "        split.append(data[last_boundary:next_boundary])\n",
    "        last_boundary = next_boundary\n",
    "    return split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def generate_dataset(seed_puzzles, solutions, boundaries, num_derivatives=0):\n",
    "    \"\"\"\n",
    "    puzzles: list of puzzle\n",
    "    \"\"\"\n",
    "    derivative_puzzles, derivative_puzzle_solutions = generate_derivatives(seed_puzzles, solutions, num_derivatives)\n",
    "\n",
    "    train_seeds, valid_seeds, test_seeds = split_data([p.stringify() for p in seed_puzzles], boundaries)\n",
    "    train_seeds_derivs = utils.flatten([derivative_puzzles[puzzle] for puzzle in train_seeds])\n",
    "    train_puzzles, valid_deriv_puzzles, test_deriv_puzzles = split_data(train_seeds_derivs, boundaries)\n",
    "\n",
    "    train = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in train_puzzles}\n",
    "    valid_deriv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in valid_deriv_puzzles}\n",
    "    test_deriv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in test_deriv_puzzles}\n",
    "\n",
    "    valid_nonderiv_puzzles = utils.flatten([derivative_puzzles[puzzle] for puzzle in valid_seeds])\n",
    "    valid_nonderiv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in valid_nonderiv_puzzles}\n",
    "    test_nonderiv_puzzles = utils.flatten([derivative_puzzles[puzzle] for puzzle in test_seeds])\n",
    "    test_nonderiv = {puzzle: derivative_puzzle_solutions[puzzle] for puzzle in test_nonderiv_puzzles}\n",
    "\n",
    "    # sanity check\n",
    "    assert not train.keys() & valid_deriv.keys()\n",
    "    assert not train.keys() & test_deriv.keys()\n",
    "    assert not train.keys() & valid_nonderiv.keys()\n",
    "    assert not train.keys() & test_nonderiv.keys()\n",
    "    assert not valid_deriv.keys() & test_deriv.keys()\n",
    "    assert not valid_deriv.keys() & valid_nonderiv.keys()\n",
    "    assert not valid_deriv.keys() & test_nonderiv.keys()\n",
    "    assert not test_deriv.keys() & valid_nonderiv.keys()\n",
    "    assert not test_deriv.keys() & test_nonderiv.keys()\n",
    "    assert not valid_nonderiv.keys() & test_nonderiv.keys()\n",
    "    \n",
    "    return train, valid_deriv, test_deriv, valid_nonderiv, test_nonderiv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train, valid_deriv, test_deriv, valid_nonderiv, test_nonderiv = generate_dataset(puzzles[4], solutions, [.7, .8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(15):\n",
    "    print('STEP: ', i)\n",
    "    def closure():\n",
    "        optimizer.zero_grad()\n",
    "        out = seq(input)\n",
    "        loss = criterion(out, target)\n",
    "        print('loss:', loss.item())\n",
    "        loss.backward()\n",
    "        return loss\n",
    "    optimizer.step(closure)\n",
    "    # begin to predict, no need to track gradient here\n",
    "    with torch.no_grad():\n",
    "        future = 1000\n",
    "        pred = seq(test_input, future=future)\n",
    "        loss = criterion(pred[:, :-future], test_target)\n",
    "        print('test loss:', loss.item())\n",
    "        y = pred.detach().numpy()\n",
    "    # draw the result\n",
    "    plt.figure(figsize=(30,10))\n",
    "    plt.title('Predict future values for time sequences\\n(Dashlines are predicted values)', fontsize=30)\n",
    "    plt.xlabel('x', fontsize=20)\n",
    "    plt.ylabel('y', fontsize=20)\n",
    "    plt.xticks(fontsize=20)\n",
    "    plt.yticks(fontsize=20)\n",
    "    def draw(yi, color):\n",
    "        plt.plot(np.arange(input.size(1)), yi[:input.size(1)], color, linewidth = 2.0)\n",
    "        plt.plot(np.arange(input.size(1), input.size(1) + future), yi[input.size(1):], color + ':', linewidth = 2.0)\n",
    "    draw(y[0], 'r')\n",
    "    draw(y[1], 'g')\n",
    "    draw(y[2], 'b')\n",
    "    plt.savefig('predict%d.pdf'%i)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "board = Board.loadFromString('2.2.0134432100400010')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 3, 4],\n",
       "       [4, 3, 2, 1],\n",
       "       [0, 0, 4, 0],\n",
       "       [0, 0, 1, 0]], dtype=int8)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "board"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.2.2134432112433412'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'2.2.2134432112433412'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def shuffle_numbers(seed_board_string, number_orders):\n",
    "    max_digit = int(seed_board_string[0]) * int(seed_board_string[2])\n",
    "    digits = seed_board_string[4:]\n",
    "    assert np.all([int(digits[i]) == i+1 or int(digits[i]) == 0 for i in range(max_digit)]) # check if seed\n",
    "    if type(number_orders) == str:\n",
    "        number_orders = [number_orders]\n",
    "        \n",
    "    all_digits = {str(i) for i in range(1, max_digit+1)}\n",
    "    shuffled_board_strings = []\n",
    "    for number_order in number_orders:\n",
    "        assert len(number_order) == max_digit\n",
    "        mapping = {str(i+1): str(number_order[i]) for i in range(max_digit)}\n",
    "        assert set(mapping.values()) == all_digits\n",
    "        shuffled_board_string = seed_board_string[:4]\n",
    "        shuffled_board_string += ''.join([mapping[d] for d in digits])\n",
    "        shuffled_board_strings.append(shuffled_board_string)\n",
    "    \n",
    "    return shuffled_board_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(range(5))[5:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
