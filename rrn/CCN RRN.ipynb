{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import itertools\n",
    "import random\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "\n",
    "import sys\n",
    "sys.path.append('/home/ajhnam/sudoku/src/sudoku')\n",
    "\n",
    "from board import Board\n",
    "from grid_string import GridString, read_solutions_file\n",
    "from shuffler import Shuffler\n",
    "from shuffled_grid import ShuffledGrid\n",
    "from solutions import Solutions\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set random seed to 0\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.set_default_tensor_type('torch.DoubleTensor')\n",
    "device = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7, 8, 1, 5, 3, 4, 2, 0, 9, 6]\n"
     ]
    }
   ],
   "source": [
    "a = list(range(10))\n",
    "random.shuffle(a)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '/home/ajhnam/sudoku/data/shuffled_puzzles.txt'\n",
    "with open(filename) as f:\n",
    "    lines = f.read().splitlines()\n",
    "puzzles = {}\n",
    "for line in lines:\n",
    "    puzzle, solution = line.split(',')\n",
    "    puzzles[GridString(puzzle)] = GridString(solution)\n",
    "puzzle_keys = list(puzzles.keys())\n",
    "random.shuffle(puzzle_keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_edges(dim_x, dim_y):\n",
    "    \"\"\"\n",
    "    Returns a 2-d array of (max_digit**2, n) where the i_th entry is a list of\n",
    "        other cells' indices that cell i shares a house with\n",
    "    \"\"\"\n",
    "    max_digit = dim_x*dim_y\n",
    "    edges = []\n",
    "    for row in range(max_digit):\n",
    "        row_edges = []\n",
    "        for col in range(max_digit):\n",
    "            # row & column\n",
    "            col_edges = {(row, i) for i in range(max_digit)}\n",
    "            col_edges |= {(i, col) for i in range(max_digit)}\n",
    "            \n",
    "            # box\n",
    "            x_min = (row // dim_x) * dim_x\n",
    "            y_min = (col // dim_y) * dim_y\n",
    "            col_edges |= set(itertools.product(range(x_min, x_min+dim_x), range(y_min, y_min+dim_y)))\n",
    "            \n",
    "            # removing self\n",
    "            col_edges -= {(row, col)}\n",
    "            col_edges = [row*max_digit + col for row, col in col_edges]\n",
    "            row_edges.append(sorted(col_edges))\n",
    "        edges.append(row_edges)\n",
    "    edges = torch.tensor(edges)\n",
    "    shape = edges.shape\n",
    "    return edges.reshape(max_digit**2, shape[2])\n",
    "\n",
    "def encode_input(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid()))\n",
    "\n",
    "def encode_output(grid_string: GridString):\n",
    "    return torch.tensor(list(grid_string.traverse_grid())) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, layer_sizes):\n",
    "        super(MLP, self).__init__()\n",
    "        self.layer_sizes = layer_sizes\n",
    "        \n",
    "        self.layers = nn.ModuleList()\n",
    "        self.nonlinear = nn.ReLU()\n",
    "        \n",
    "        prev_layer_size = self.layer_sizes[0]\n",
    "        for size in self.layer_sizes[1:]:\n",
    "            self.layers.append(nn.Linear(prev_layer_size, size))\n",
    "            prev_layer_size = size\n",
    "\n",
    "    def forward(self, X):\n",
    "        vector = X\n",
    "        for layer in self.layers[:-1]:\n",
    "#             vector = layer(vector)\n",
    "            vector = self.nonlinear(layer(vector))\n",
    "        return self.layers[-1](vector)\n",
    "\n",
    "class RRN(nn.Module):\n",
    "    def __init__(self, dim_x, dim_y, embed_size=16, hidden_layer_size=96):\n",
    "        super(RRN, self).__init__()\n",
    "        self.max_digit = dim_x * dim_y\n",
    "        self.embed_size = embed_size\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        \n",
    "        self.edges = determine_edges(dim_x, dim_y)\n",
    "\n",
    "\n",
    "        self.embed_layer = nn.Embedding(self.max_digit+1, self.embed_size)\n",
    "        self.input_mlp = MLP([self.embed_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size,\n",
    "                              self.hidden_layer_size])\n",
    "        \n",
    "        self.f = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_mlp = MLP([2*self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size])\n",
    "        self.g_lstm = nn.LSTM(self.hidden_layer_size, self.hidden_layer_size)\n",
    "        self.r = MLP([self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.hidden_layer_size,\n",
    "                      self.max_digit])\n",
    "    \n",
    "    def compute_messages(self, H):\n",
    "        messages = torch.zeros(H.shape)\n",
    "        batch_size = H.shape[0]\n",
    "        num_nodes = H.shape[1]\n",
    "        for puzzle_index in range(batch_size): # for puzzle in batch\n",
    "            messages[puzzle_index] = torch.tensor([torch.sum(H[puzzle_index][self.edges[n]]) for n in range(num_nodes)])\n",
    "        return messages\n",
    "                    \n",
    "\n",
    "    def forward(self, grids, iters):\n",
    "        batch_size = len(grids)\n",
    "        num_nodes = self.max_digit**2\n",
    "        edges_per_nodes = self.edges.shape[1]\n",
    "        \n",
    "        embeddings = self.embed_layer(grids)\n",
    "        X = self.input_mlp(embeddings)\n",
    "        H = torch.tensor(X).cuda(device)\n",
    "        g_lstm_h = H.reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "        g_lstm_c = torch.randn(1, batch_size*num_nodes, self.hidden_layer_size).cuda(device)\n",
    "        \n",
    "        outputs = []\n",
    "        for i in range(iters):\n",
    "            M = torch.zeros(batch_size, self.max_digit**2, self.hidden_layer_size).cuda(device)\n",
    "            for node in range(num_nodes):\n",
    "                msgs = torch.cat([self.f(torch.cat([H[:,node,:], H[:,other,:]], dim=1)) for other in self.edges[node]])\n",
    "                msgs = msgs.reshape(edges_per_nodes, batch_size, self.hidden_layer_size).permute(1,0,2)\n",
    "                M[:,node,:] = torch.sum(msgs, dim=1)\n",
    "            \n",
    "            input_to_g_lstm = self.g_mlp(torch.cat([X, M], dim=2)).reshape(1, batch_size*num_nodes, self.hidden_layer_size)\n",
    "            \n",
    "            _, (g_lstm_h, g_lstm_c) = self.g_lstm(input_to_g_lstm, (g_lstm_h, g_lstm_c))\n",
    "            H = g_lstm_h.reshape(H.shape)\n",
    "            output = self.r(H)\n",
    "            \n",
    "            outputs.append(output)\n",
    "                \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_n = 1000\n",
    "train_puzzles = puzzle_keys[0:train_n]\n",
    "\n",
    "train_solutions = [puzzles[p] for p in train_puzzles]\n",
    "\n",
    "max_digit = train_puzzles[0].max_digit\n",
    "num_cells = max_digit**2\n",
    "cell_vec_dim = max_digit + 1\n",
    "train_x = torch.cat([encode_input(p) for p in train_puzzles]).reshape(train_n, num_cells).cuda(device)\n",
    "train_y = torch.cat([encode_output(p) for p in train_solutions]).reshape(train_n, num_cells).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = RRN( dim_x=2, dim_y=2, embed_size=6, hidden_layer_size=32).cuda(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f42329d0749e4298bc900c282a163492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=250), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(44.4890, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.4717, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.4548, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.4397, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.4235, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.4076, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3924, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3800, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3691, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3602, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3502, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3387, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3276, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3153, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.3026, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.2935, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.2757, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.2490, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.2118, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.1669, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.1148, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(44.0609, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.9825, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.8758, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.7464, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.6113, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.4400, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(43.2264, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(42.9613, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(42.6497, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(42.2827, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(41.9066, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(41.5012, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(41.0308, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(40.4159, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(40.0072, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(39.3605, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(38.9037, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(38.3906, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(37.8466, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(37.3677, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(36.7620, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(36.2170, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(35.7118, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(35.1293, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(34.6290, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(34.1799, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(33.9452, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(33.3727, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(33.1941, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(32.8801, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(32.5185, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(32.3279, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(32.0831, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(31.7331, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(31.5273, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(31.1906, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(31.1404, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(30.8612, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(30.7255, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(30.3937, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(30.1303, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(30.0575, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(29.6743, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(29.5685, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(29.3241, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(29.1599, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.9352, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.7293, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.5749, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.4860, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.2725, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(28.0252, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.9746, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.7345, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.6607, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.5311, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.4767, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.3520, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.3522, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.3199, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.2412, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.1591, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.1606, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0369, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0176, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0460, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0112, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0833, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(27.0422, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.9954, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.9783, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.9845, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.9223, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8952, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8865, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.9367, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8744, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8977, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8837, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8527, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8245, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.8222, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.7263, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.7085, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.6844, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.6494, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.6816, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.5969, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.5794, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.4832, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.5031, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.4129, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.3200, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.3257, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.2335, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.2183, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.1438, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(26.1259, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.9922, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.9962, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.8546, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.7583, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.5961, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.4367, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.2826, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(25.1597, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(24.9838, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(24.7795, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(24.5665, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(24.2909, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(24.0388, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(23.8348, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(23.5584, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(23.3223, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(23.1146, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(22.8070, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(22.5094, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(22.3625, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(22.2223, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(21.9569, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(21.7298, device='cuda:1', grad_fn=<ThAddBackward>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(21.5902, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(21.3358, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(21.1536, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(20.8570, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(20.7575, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(20.4796, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(20.3180, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(20.2598, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(19.7587, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(19.5186, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(18.8968, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(18.3984, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(18.1597, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(17.8333, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(17.8072, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(17.0278, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(16.7682, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(16.4474, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(16.2000, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(16.0436, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(15.8950, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(15.7911, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(15.2343, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(15.0493, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.8522, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.6955, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.4962, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.3298, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.1132, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.9445, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.1508, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.3189, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.4907, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(14.0224, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.6809, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7114, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7094, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7147, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.6854, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7314, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.8327, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7504, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.8963, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7565, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.7976, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.6806, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.6134, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.5906, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.5700, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.4382, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.3768, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.2360, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.1587, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.2071, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.0326, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.9681, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.9066, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.9503, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.9792, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(13.1252, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.7914, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.9268, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.7845, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.8631, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.6955, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.7053, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.6336, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.5851, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.7375, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.6153, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.6729, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.5854, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.6304, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4018, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4315, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4148, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4487, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3724, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4291, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4742, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4552, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4236, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.5648, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.4162, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3495, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3554, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3153, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3639, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3386, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2455, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2166, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3151, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1886, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2848, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1471, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2453, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3428, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1394, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1373, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2379, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.3120, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2416, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.2267, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.0283, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.0524, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1213, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "tensor(12.1611, device='cuda:1', grad_fn=<ThAddBackward>)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = [p.permute(0,2,1) for p in model(train_x, 32)]\n",
    "    loss = sum([F.cross_entropy(p, train_y) for p in predictions])\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in tqdm_notebook(range(250)):\n",
    "    print(optimizer.step(closure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./250.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RRN(\n",
       "  (embed_layer): Embedding(5, 6)\n",
       "  (input_mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=6, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (nonlinear): ReLU()\n",
       "  )\n",
       "  (f): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (nonlinear): ReLU()\n",
       "  )\n",
       "  (g_mlp): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=32, bias=True)\n",
       "    )\n",
       "    (nonlinear): ReLU()\n",
       "  )\n",
       "  (g_lstm): LSTM(32, 32)\n",
       "  (r): MLP(\n",
       "    (layers): ModuleList(\n",
       "      (0): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "      (2): Linear(in_features=32, out_features=4, bias=True)\n",
       "    )\n",
       "    (nonlinear): ReLU()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = RRN( dim_x=2, dim_y=2, embed_size=6, hidden_layer_size=32).cuda(device)\n",
    "model2.load_state_dict(torch.load(\"./250.pth\"), strict=False)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_n = 1000\n",
    "test_puzzles = puzzle_keys[train_n:train_n+test_n]\n",
    "test_solutions = [puzzles[p] for p in test_puzzles]\n",
    "\n",
    "test_x = torch.cat([encode_input(p) for p in test_puzzles]).reshape(test_n, num_cells).cuda(device)\n",
    "test_y = torch.cat([encode_output(p) for p in test_solutions]).reshape(test_n, num_cells).cuda(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax = nn.Softmax(dim=2)\n",
    "predictions = [softmax(p) for p in model2(test_x, 32)]\n",
    "output = predictions[-1].argmax(dim=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model2.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    predictions = [p.permute(0,2,1) for p in model(train_x, 32)]\n",
    "    loss = sum([F.cross_entropy(p, train_y) for p in predictions])\n",
    "    loss.backward()\n",
    "    return loss\n",
    "\n",
    "for i in tqdm_notebook(range(250)):\n",
    "    print(optimizer.step(closure))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 3, 1, 2, 2, 1, 0, 3, 1, 2, 3, 4, 0, 4, 2, 1], device='cuda:1')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 2, 0, 1, 1, 0, 3, 2, 0, 1, 2, 3, 2, 3, 1, 0], device='cuda:1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {
    "dd0518e8c4b848a7aaf902e08c2f8858": {
     "views": [
      {
       "cell_index": 8
      }
     ]
    }
   },
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
